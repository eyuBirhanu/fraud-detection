{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f919ba4-c983-4f45-87da-045d6f51cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.preprocess import load_data, clean_data, feature_engineering, merge_geolocation\n",
    "\n",
    "# Modeling Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "\n",
    "# Imbalance Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "\n",
    "print(\"Libraries Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fc075a-7626-4eb1-bb12-26de30d72842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-26 06:19:05,150 - INFO - Data loaded successfully from ../data/raw/Fraud_Data.csv. Shape: (151112, 11)\n",
      "2025-12-26 06:19:05,365 - INFO - Data loaded successfully from ../data/raw/IpAddress_to_Country.csv. Shape: (138846, 3)\n",
      "2025-12-26 06:19:06,897 - INFO - Starting Geolocation Merge...\n",
      "2025-12-26 06:19:07,127 - INFO - Geolocation Merge Completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (151112, 9)\n"
     ]
    }
   ],
   "source": [
    "# Re-load and process if variables aren't in memory\n",
    "fraud_df = load_data('../data/raw/Fraud_Data.csv')\n",
    "ip_df = load_data('../data/raw/IpAddress_to_Country.csv')\n",
    "fraud_df = clean_data(fraud_df)\n",
    "fraud_df = feature_engineering(fraud_df)\n",
    "fraud_df = merge_geolocation(fraud_df, ip_df)\n",
    "\n",
    "# Define Features\n",
    "X = fraud_df.drop(['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', \n",
    "                   'ip_address', 'ip_address_int', 'lower_bound_ip_address', \n",
    "                   'upper_bound_ip_address'], axis=1)\n",
    "y = fraud_df['class']\n",
    "\n",
    "# Define Categorical vs Numerical\n",
    "categorical_cols = ['source', 'browser', 'sex', 'country']\n",
    "numerical_cols = ['purchase_value', 'age', 'time_since_signup', 'hour_of_day']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92788e4f-5fde-4a20-9511-5e4ac6c6ec42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "# 1. Split Data (Stratified because of imbalance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 2. Create Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# 3. Create Model Pipeline with SMOTE\n",
    "# SMOTE is used inside the pipeline so it only upsamples the Training Data, not Test Data!\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 4. Train\n",
    "print(\"Training Random Forest...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749f5967-2283-450d-a310-344593fb452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     27393\n",
      "           1       0.82      0.53      0.64      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.89      0.76      0.81     30223\n",
      "weighted avg       0.94      0.95      0.94     30223\n",
      "\n",
      "Area Under Precision-Recall Curve (AUPRC): 0.6967\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Report\n",
    "print(\"--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUPRC (Better for imbalance than Accuracy)\n",
    "# Note: Need to encode y_test/pred if using simple sklearn metric, \n",
    "# but for binary 0/1 it works directly.\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "auprc = auc(recall, precision)\n",
    "print(f\"Area Under Precision-Recall Curve (AUPRC): {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae070079-818c-44ba-b06c-759f4883b476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
